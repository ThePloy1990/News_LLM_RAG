# Отчет о RAG-системе для криптовалютной аналитики

## Содержание
1. [Введение](#введение)
2. [Архитектура системы](#архитектура-системы)
3. [Сравнительный анализ моделей](#сравнительный-анализ-моделей)
4. [Детальный анализ модели Qwen](#детальный-анализ-модели-qwen)
5. [Сильные и слабые стороны проекта](#сильные-и-слабые-стороны-проекта)
6. [Рекомендации по улучшению](#рекомендации-по-улучшению)
7. [Заключение](#заключение)

## Введение

Данный отчет представляет анализ Retrieval-Augmented Generation (RAG) системы, специализированной на анализе информации о криптовалютах и блокчейне. Система разработана для предоставления точных, основанных на фактах ответов на вопросы пользователей, опираясь исключительно на проверенные источники информации.

Система использует комбинацию векторного поиска для извлечения релевантных документов и языковые модели для генерации структурированных ответов на основе найденной информации. Поддерживаются режимы вопрос-ответ (qa) и сравнительного анализа мнений (compare).

## Архитектура системы

### Принципы проектирования

Проект реализован согласно следующим архитектурным принципам:

1. **Модульность** — система разделена на чётко очерченные компоненты
2. **Гибкость в выборе моделей** — поддержка различных языковых моделей через единый интерфейс
3. **Масштабируемость** — возможность расширения функционала без переписывания существующего кода
4. **Отказоустойчивость** — наличие запасных механизмов при сбоях отдельных компонентов

### Основные компоненты

#### Векторное хранилище (Vector Store)
- **Основная технология**: FAISS (Facebook AI Similarity Search)
- **Резервная реализация**: SimpleVectorStore
- **Особенности**:
  - Поддержка GPU-акселерации
  - Фильтрация документов по криптовалютной тематике
  - Балансировка источников для разнообразия мнений

#### Модуль эмбеддингов
- **Технология**: HuggingFaceEmbeddings с моделью sentence-transformers/all-MiniLM-L6-v2
- **Применение**: Поиск релевантных документов и оценка семантической близости

#### Языковые модели (LLM)
- **Реализованные модели**:
  - **PhiLLM** — обёртка для модели Phi-3 Mini от Microsoft
  - **QwenLLM** — обёртка для модели Qwen от Alibaba
- **Фабрика моделей**: LLMFactory обеспечивает универсальный интерфейс

#### RAG-пайплайн
- **Компоненты процесса**:
  - Поиск релевантных документов
  - Фильтрация по тематике
  - Балансировка источников
  - Генерация структурированного ответа
- **Режимы работы**: qa и compare

#### Система бенчмаркинга
- **Модули**: model_performance.py, rag_quality.py, run_benchmarks.py
- **Метрики**: время выполнения, успешность запросов, покрытие ключевых слов, частота цитирования, объём ответов

### Процесс обработки запроса

1. **Получение запроса** от пользователя
2. **Поиск релевантных документов** в векторном хранилище
3. **Фильтрация документов** по криптовалютной тематике
4. **Балансировка источников** для обеспечения разнообразия информации
5. **Формирование промпта** с контекстом
6. **Генерация ответа** выбранной моделью
7. **Форматирование ответа** в структурированный вид

## Сравнительный анализ моделей

### Результаты бенчмаркинга производительности

| Модель | Среднее время | Минимальное время | Максимальное время | Успешность запросов|
|--------|---------------|-------------------|--------------------|--------------------|
| Phi-3  | 65,48 сек     | 30,03 сек         | 100,93 сек          | 100%               |
| Qwen   | 26,33 сек     | 23,29 сек         | 28,23 сек          | 100%               |

### Ключевые наблюдения

- Модель Qwen демонстрирует превосходство в скорости, работая в **2 раза быстрее**, чем Phi-3
- Обе модели обрабатывают 100% запросов успешно
- Увеличение времени обработки у Phi при усложнении запросов
- Qwen показывает стабильное время генерации независимо от сложности запроса

### Анализ качества ответов

Из завершенного теста качества:

- **Покрытие ключевых слов для Phi**:
  - Вопрос о перспективах Ethereum по мнению VitalikButerin за март 2025: 0% 
  - Вопрос о факторах цены Bitcoin в марте 2025, учитывая новостные манипуляции на рынказ США: 10%
  - Нерелевантный вопрос о пицце: 12,5% 
- **Цитирование источников**: Phi правильно цитирует источники только для первого вопроса
- **Длина ответов Phi**: 1500-2700 символов (200-340 слов)
- **Длина ответов Qwen**: 1200-1400 символов (200-250 слов)

## Детальный анализ модели Qwen

### Общие характеристики

**Qwen** продемонстрировала исключительную производительность в рамках тестирования системы. Используемая версия - **Qwen/Qwen1.5-7B-Chat**.

### Временные характеристики

| Метрика | Значение |
|---------|----------|
| Среднее время ответа | 26.33 сек |
| Минимальное время | 23.29 сек |
| Максимальное время | 28.23 сек |
| Стабильность времени | Высокая (разброс ~5 сек) |

### Ресурсопотребление

- **Загрузка модели**: ~166 сек
- **Использование GPU-памяти**: 5.82 ГБ из 14.74 ГБ доступной на Tesla T4
- **Сравнение с Phi-3**: Более эффективна (5.82 ГБ против 7.20 ГБ)

### Преимущества Qwen

1. **Превосходная скорость генерации** для RAG-задач
2. **Стабильное время отклика** независимо от сложности запроса
3. **Меньшее потребление GPU-памяти** по сравнению с Phi-3

- **Покрытие ключевых слов для Qwen**:
  - Вопрос о перспективах Ethereum по мнению VitalikButerin за март 2025: 40% 
  - Вопрос о факторах цены Bitcoin в марте 2025, учитывая новостные манипуляции на рынказ США: 60%
  - Нерелевантный вопрос о пицце: 30%

## Сильные и слабые стороны проекта

### Сильные стороны

1. **Гибкая мультимодельная архитектура**
   - Система поддерживает различные LLM с единым интерфейсом
   - Легко расширяемая фабрика моделей

2. **Продвинутая реализация RAG-пайплайна**
   - Интеллектуальная фильтрация документов
   - Балансировка источников для обеспечения разнообразия мнений
   - Структурированные ответы с разделами

3. **Отказоустойчивость**
   - Обработка исключений на различных уровнях
   - Альтернативное простое векторное хранилище при недоступности FAISS
   - Адаптивные механизмы генерации

4. **Развитая система бенчмаркинга**
   - Комплексное тестирование производительности и качества
   - Детальная аналитика с визуализацией результатов
   - Разнообразные типы тестовых запросов

### Слабые стороны

1. **Критические проблемы производительности Phi-3**
   - Отключение кэширования из-за ошибки `DynamicCache` приводит к чрезвычайно долгой генерации (я хз почему так)

2. **Обработка нерелевантных запросов**
   - Система не отклоняет нерелевантные запросы (пример с вопросом о пицце)
   - Попытка ответить вместо объяснения ограничений, хотя общий ответ со смыслом "нерелевантный запрос"

## Рекомендации по улучшению

1. **Модернизация кодовой базы**
   - Оптимизация параллельной обработки запросов

3. **Улучшение интеллекта системы**
   - Внедрение предварительной классификации запросов по релевантности
   - Переработка промптов для лучшего соблюдения инструкций
   - Разработка более продвинутых метрик оценки качества

4. **Расширение функциональности**
   - Добавление новых моделей, включая более компактные для быстрых запросов