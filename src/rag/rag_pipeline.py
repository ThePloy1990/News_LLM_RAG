import os
from typing import List, Dict, Any, Optional, Union
from dotenv import load_dotenv
from langchain_community.embeddings import HuggingFaceEmbeddings
# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º FAISS —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –≤–æ–∑–º–æ–∂–Ω–æ–π –æ—à–∏–±–∫–∏
try:
    from langchain_community.vectorstores import FAISS
    FAISS_AVAILABLE = True
except ImportError:
    print("–ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–ï: –ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å FAISS. –ë—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ —É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞.")
    FAISS_AVAILABLE = False
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain.output_parsers import PydanticOutputParser
from pydantic import BaseModel, Field
import re
from langchain.schema import Document
from langchain.vectorstores.base import VectorStore

from .llm_factory import LLMFactory
from .models import RAGResponse

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# –°–ø–∏—Å–æ–∫ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–Ω–æ–π —Ç–µ–º–∞—Ç–∏–∫–µ
CRYPTO_KEYWORDS = [
    # –û—Å–Ω–æ–≤–Ω—ã–µ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç—ã
    '–±–∏—Ç–∫–æ–∏–Ω', 'bitcoin', 'btc', 'eth', 'ethereum', '—ç—Ñ–∏—Ä–∏—É–º',
    '–∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–∞', 'crypto', '–±–ª–æ–∫—á–µ–π–Ω', 'blockchain',
    
    # –ê–ª—å—Ç–∫–æ–∏–Ω—ã –∏ —Ç–æ–∫–µ–Ω—ã
    '–∞–ª—å—Ç–∫–æ–∏–Ω', 'altcoin', '—Ç–æ–∫–µ–Ω', 'token', 'nft', 'defi', 'dao',
    'solana', 'sol', 'cardano', 'ada', 'binance', 'bnb', 'xrp', 'ripple',
    'polkadot', 'dot', 'avalanche', 'avax', 'tether', 'usdt', 'stablecoin',
    
    # –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –∏ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏
    '–º–∞–π–Ω–∏–Ω–≥', 'mining', '—Å—Ç–µ–π–∫–∏–Ω–≥', 'staking', 'proof of stake', 'pos',
    'proof of work', 'pow', 'consensus', '–∫–æ–Ω—Å–µ–Ω—Å—É—Å', '—Å–º–∞—Ä—Ç-–∫–æ–Ω—Ç—Ä–∞–∫—Ç',
    'smart contract', 'layer 2', 'l2', 'rollup', 'scaling', 'scalability',
    '—à–∞—Ä–¥–∏–Ω–≥', 'sharding', 'web3', '–≤–µ–±3', 'dapp', '–¥–µ—Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–∞—Ü–∏—è', 
    'decentralization', '–¥–µ—Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π', 'centralized', '—Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π',
    'p2p', '–ø–∏—Ä–∏–Ω–≥–æ–≤—ã–π', 'cross-chain', '–∫—Ä–æ—Å—Å—á–µ–π–Ω', 'interoperability',
    
    # –û–±–º–µ–Ω –∏ —Ç–æ—Ä–≥–æ–≤–ª—è
    '–±–∏—Ä–∂–∞', 'exchange', 'dex', 'swap', 'amm', 'liquidity', '–ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å',
    'trading', '—Ç—Ä–µ–π–¥–∏–Ω–≥', 'market', '—Ä—ã–Ω–æ–∫', '—Å–ø–æ—Ç', 'spot', 'futures', '—Ñ—å—é—á–µ—Ä—Å—ã',
    'options', '–æ–ø—Ü–∏–æ–Ω—ã', '–≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å', 'volatility', 'bull', '–º–µ–¥–≤–µ–∂–∏–π',
    'bear', '–±—ã—á–∏–π', 'pump', 'dump', 'yield', 'farming', '–º–∞–π–Ω–µ—Ä', 'miner',
    
    # –†–µ–≥—É–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ —ç–∫–æ–Ω–æ–º–∏–∫–∞
    '—Ä–µ–≥—É–ª–∏—Ä–æ–≤–∞–Ω–∏–µ', 'regulation', 'sec', '—Ü–±', '—Ü–µ–Ω—Ç—Ä–æ–±–∞–Ω–∫', '—Å–∞–Ω–∫—Ü–∏–∏',
    'sanctions', 'compliance', 'kyc', 'aml', '–Ω–∞–ª–æ–≥', 'tax', '–∑–∞–∫–æ–Ω–æ–ø—Ä–æ–µ–∫—Ç',
    '–∑–∞–ø—Ä–µ—Ç', 'ban', '–ª–µ–≥–∞–ª–∏–∑–∞—Ü–∏—è', 'adoption', 'adoption', '—Ü–∏—Ñ—Ä–æ–≤–∞—è —ç–∫–æ–Ω–æ–º–∏–∫–∞',
    '—Ü–∏—Ñ—Ä–æ–≤–æ–π —Ä—É–±–ª—å', 'cbdc', '–∏–Ω—Ñ–ª—è—Ü–∏—è', 'inflation', 'hedge', '—Ö–µ–¥–∂',
    
    # –ü–µ—Ä—Å–æ–Ω–∞–ª–∏–∏ –∏ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏
    'vitalik', 'buterin', '–≤–∏—Ç–∞–ª–∏–∫', '–±—É—Ç–µ—Ä–∏–Ω', 'satoshi', 'nakamoto', '—Å–∞—Ç–æ—à–∏',
    '–Ω–∞–∫–∞–º–æ—Ç–æ', 'chainanlysis', 'consensys', 'grayscale', 'microstrategy', 'saylor',
    'cz', '—á–∞–Ω–ø—ç–Ω', 'binance', '–±–∏–Ω–∞–Ω—Å', 'coinbase', 'kraken', 'ftx', 'sbf',
    'bankman-fried', 'celsius', 'metamask', 'opensea', 'uniswap', 'aave',
    'compound', 'makerdao', 'arbitrum', 'optimism'
]

class Opinion(BaseModel):
    """–ú–æ–¥–µ–ª—å –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞ –º–Ω–µ–Ω–∏–π."""
    author: str = Field(description="–ê–≤—Ç–æ—Ä –º–Ω–µ–Ω–∏—è")
    sentiment: str = Field(description="–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –º–Ω–µ–Ω–∏—è (–ø–æ–∑–∏—Ç–∏–≤–Ω–∞—è/–Ω–µ–≥–∞—Ç–∏–≤–Ω–∞—è/–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è)")
    key_points: List[str] = Field(description="–ö–ª—é—á–µ–≤—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∞–≤—Ç–æ—Ä–∞")
    confidence: float = Field(description="–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –∞–Ω–∞–ª–∏–∑–µ (–æ—Ç 0 –¥–æ 1)")


# –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Å—Ç–æ–≥–æ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞, –µ—Å–ª–∏ FAISS –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
class SimpleVectorStore:
    """–ü—Ä–æ—Å—Ç–∞—è –∑–∞–º–µ–Ω–∞ FAISS –¥–ª—è —Å–ª—É—á–∞–µ–≤, –∫–æ–≥–¥–∞ FAISS –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"""
    def __init__(self, embeddings, documents):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Å—Ç–æ–≥–æ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞"""
        self.embeddings = embeddings
        self.documents = documents if documents else []
        self.document_embeddings = []
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        if documents:
            texts = [doc.page_content for doc in documents]
            self.document_embeddings = embeddings.embed_documents(texts)
    
    def similarity_search(self, query, k=5):
        """–ü–æ–∏—Å–∫ k –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ—Ö–æ–∂–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
        import numpy as np
        from sklearn.metrics.pairwise import cosine_similarity
        
        # –ï—Å–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –Ω–µ—Ç, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫
        if not self.documents:
            return []
        
        # –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
        query_embedding = self.embeddings.embed_query(query)
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ numpy –º–∞—Å—Å–∏–≤—ã
        query_embedding_np = np.array(query_embedding).reshape(1, -1)
        document_embeddings_np = np.array(self.document_embeddings)
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ
        similarities = cosine_similarity(query_embedding_np, document_embeddings_np).flatten()
        
        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã k –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ—Ö–æ–∂–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        indices = np.argsort(similarities)[::-1][:k]
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ—Ö–æ–∂–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
        return [self.documents[i] for i in indices]
    
    @classmethod
    def load_local(cls, folder_path, embeddings, allow_dangerous_deserialization=False):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑ –ª–æ–∫–∞–ª—å–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏"""
        import pickle
        import os
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ —Ñ–∞–π–ª–∞
        docs_path = os.path.join(folder_path, "documents.pkl")
        if os.path.exists(docs_path):
            with open(docs_path, "rb") as f:
                documents = pickle.load(f)
        else:
            print("–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: —Ñ–∞–π–ª documents.pkl –Ω–µ –Ω–∞–π–¥–µ–Ω")
            documents = []
        
        return cls(embeddings, documents)


class RAGPipeline:
    def __init__(self, index_path: str = "faiss_index", model_id: str = "phi", use_gpu: bool = True, **model_kwargs):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG-–ø–∞–π–ø–ª–∞–π–Ω–∞.
        
        Args:
            index_path: –ü—É—Ç—å –∫ –∏–Ω–¥–µ–∫—Å—É FAISS
            model_id: ID —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª–∏ ('phi', 'gemma', 'qwen', 'saiga')
            use_gpu: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ GPU –¥–ª—è FAISS (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ)
            **model_kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª–∏
        """
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º SentenceTransformers –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        self.embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/all-MiniLM-L6-v2"
        )
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å CUDA –¥–ª—è FAISS
        self.use_gpu = False  # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –æ—Ç–∫–ª—é—á–∞–µ–º GPU –¥–ª—è FAISS –∏–∑-–∑–∞ –ø—Ä–æ–±–ª–µ–º —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        self.gpu_available = False
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
        try:
            if FAISS_AVAILABLE:
                self.vectorstore = FAISS.load_local(index_path, self.embeddings, allow_dangerous_deserialization=True)
                print("–ò–Ω–¥–µ–∫—Å FAISS —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω")
            else:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç—É—é –∑–∞–º–µ–Ω—É FAISS
                print("–ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç–æ–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –≤–º–µ—Å—Ç–æ FAISS")
                self.vectorstore = SimpleVectorStore.load_local(index_path, self.embeddings)
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∏–Ω–¥–µ–∫—Å–∞: {e}")
            import traceback
            traceback.print_exc()
            # –°–æ–∑–¥–∞–µ–º –ø—É—Å—Ç–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
            if FAISS_AVAILABLE:
                self.vectorstore = FAISS.from_texts(["–ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏"], self.embeddings)
            else:
                self.vectorstore = SimpleVectorStore(self.embeddings, [Document(page_content="–ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏", metadata={"author": "—Å–∏—Å—Ç–µ–º–∞", "date": "—Å–µ–≥–æ–¥–Ω—è"})])
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º LLM —á–µ—Ä–µ–∑ —Ñ–∞–±—Ä–∏–∫—É
        self.llm = LLMFactory.get_model(model_id, **model_kwargs)
        
        if not self.llm:
            # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∑–∞–ø—Ä–æ—à–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º Phi –∫–∞–∫ –∑–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç
            print(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å '{model_id}', –∏—Å–ø–æ–ª—å–∑—É—é Phi –∫–∞–∫ –∑–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç")
            self.llm = LLMFactory.get_model("phi")
        
        self.parser = PydanticOutputParser(pydantic_object=RAGResponse)
        
        print(f"–ú–æ–¥–µ–ª—å {self.llm.model_name} –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞, —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.llm.device}")
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ CUDA –¥–ª—è –º–æ–¥–µ–ª–∏ 
        try:
            import torch
            if torch.cuda.is_available() and use_gpu:
                print(f"LLM –∏—Å–ø–æ–ª—å–∑—É–µ—Ç GPU: {torch.cuda.get_device_name(0)}")
                print(f"–î–æ—Å—Ç—É–ø–Ω–∞—è –ø–∞–º—è—Ç—å GPU: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} –ì–ë")
                print(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º–∞—è –ø–∞–º—è—Ç—å GPU: {torch.cuda.memory_allocated(0) / 1024**3:.2f} –ì–ë")
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –ø–∞–º—è—Ç–∏ GPU: {e}")

    def get_relevant_documents(self, query: str, k: int = 5) -> List[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤."""
        docs = self.vectorstore.similarity_search(query, k=k)
        return [doc.metadata for doc in docs]

    def generate_qa_response(self, query: str) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º RAG."""
        # –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        print(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: {query}")
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º –±–æ–ª—å—à–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            docs = self.vectorstore.similarity_search(query, k=15)
            
            if not docs or len(docs) == 0:
                return self._format_error_response("–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É")
            
            # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∫ —Ç–µ–º–µ
            filtered_docs = []
            for doc in docs:
                text = doc.page_content.lower()
                if any(keyword in text for keyword in CRYPTO_KEYWORDS) or 'vitalik' in doc.metadata['author'].lower():
                    filtered_docs.append(doc)
            
            # –ï—Å–ª–∏ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –æ—Å—Ç–∞–ª–æ—Å—å –º–∞–ª–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, –≤–µ—Ä–Ω–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ
            if len(filtered_docs) < 3:
                filtered_docs = docs[:15]  # –í–æ–∑—å–º–µ–º —Ö–æ—Ç—è –±—ã –ø–µ—Ä–≤—ã–µ 15
                print("–ú–∞–ª–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –æ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–∞—Ö –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")
            else:
                print(f"–û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ {len(filtered_docs)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –æ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–∞—Ö")
            
            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –∞–≤—Ç–æ—Ä–∞–º –¥–ª—è –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è
            authors_map = {}
            for doc in filtered_docs:
                author = doc.metadata["author"]
                if author not in authors_map:
                    authors_map[author] = []
                authors_map[author].append(doc)

            # –ë–µ—Ä–µ–º –º–∞–∫—Å. 3 –¥–æ–∫—É–º–µ–Ω—Ç–∞ –æ—Ç –∫–∞–∂–¥–æ–≥–æ –∞–≤—Ç–æ—Ä–∞ –¥–ª—è –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è
            balanced_docs = []
            for author, author_docs in authors_map.items():
                balanced_docs.extend(author_docs[:3])
            
            # –ï—Å–ª–∏ –ø–æ—Å–ª–µ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ –æ—Å—Ç–∞–ª–æ—Å—å –º–∞–ª–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, –¥–æ–ø–æ–ª–Ω–∏–º –∏–∑ –æ–±—â–µ–≥–æ –ø—É–ª–∞
            if len(balanced_docs) < 3 and len(filtered_docs) >= 3:
                balanced_docs = filtered_docs[:15]  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã, –µ—Å–ª–∏ –∏—Ö –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ
            final_docs = balanced_docs if balanced_docs else filtered_docs[:15]
            
            # –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            print(f"–ò—Å–ø–æ–ª—å–∑—É—é {len(final_docs)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –æ—Ç {len(authors_map)} –∞–≤—Ç–æ—Ä–æ–≤")
            
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
            formatted_context = []
            for doc in final_docs:
                author = doc.metadata["author"]
                date = doc.metadata["date"]
                formatted_context.append(f"–ê–≤—Ç–æ—Ä: {author}\n–î–∞—Ç–∞: {date}\n–¢–µ–∫—Å—Ç: {doc.page_content}\n")
            
            context_text = "\n---\n".join(formatted_context)
            
            # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª–∏
            template = """
            –¢—ã - –æ–ø—ã—Ç–Ω—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–Ω–æ–≥–æ —Ä—ã–Ω–∫–∞ —Å –≥–ª—É–±–æ–∫–∏–º –ø–æ–Ω–∏–º–∞–Ω–∏–µ–º —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π –±–ª–æ–∫—á–µ–π–Ω. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –¢–û–õ–¨–ö–û –Ω–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤.
            
            –í–û–ü–†–û–°: {question}
            
            –ò–ù–§–û–†–ú–ê–¶–ò–Ø –ò–ó –ò–°–¢–û–ß–ù–ò–ö–û–í:
            {context}
            
            –í–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏ –æ—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. –í —Å–≤–æ–µ–º –æ—Ç–≤–µ—Ç–µ:
            1. –ò—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û —Ñ–∞–∫—Ç—ã –∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤, –Ω–µ –¥–æ–±–∞–≤–ª—è–π –≤–Ω–µ—à–Ω–µ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–ª–∏ —Å–≤–æ–∏—Ö –∑–Ω–∞–Ω–∏–π
            2. –ï—Å–ª–∏ –≤ —Ç–µ–∫—Å—Ç–∞—Ö –Ω–µ—Ç –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å, —á–µ—Å—Ç–Ω–æ —Å–æ–æ–±—â–∏ –æ–± —ç—Ç–æ–º
            3. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–≤–∞, —É–∫–∞–∂–∏ –Ω–∞ —Ä–∞–∑–Ω—ã–µ —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è
            4. –£–∫–∞–∂–∏ –∞–≤—Ç–æ—Ä–æ–≤ –∏ –¥–∞—Ç—ã –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
            5. –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –Ω–µ –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–∞–º –∏–ª–∏ –±–ª–æ–∫—á–µ–π–Ω—É, –≤–µ–∂–ª–∏–≤–æ –æ–±—ä—è—Å–Ω–∏, —á—Ç–æ –º–æ–∂–µ—à—å –æ—Ç–≤–µ—á–∞—Ç—å —Ç–æ–ª—å–∫–æ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ —ç—Ç–æ–π —Ç–µ–º–∞—Ç–∏–∫–µ
            
            –°–¢–†–£–ö–¢–£–†–ê –û–¢–í–ï–¢–ê (—Å–ª–µ–¥—É–π –µ–π —Å—Ç—Ä–æ–≥–æ):
            
            –ö–†–ê–¢–ö–ò–ô –û–¢–í–ï–¢: (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, —Å—É–º–º–∏—Ä—É—é—â–∏—Ö –∫–ª—é—á–µ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é)
            
            –û–°–ù–û–í–ù–´–ï –¢–ï–ú–´ –ò –§–ê–ö–¢–´:
            ‚Ä¢ –§–∞–∫—Ç 1 –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
            ‚Ä¢ –§–∞–∫—Ç 2 –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
            ‚Ä¢ –§–∞–∫—Ç 3 –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ (–∏ —Ç.–¥.)
            
            –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï: (3-4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –æ–±–æ–±—â–∞—é—â–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—â–∏–µ —Ü–µ–ª–æ—Å—Ç–Ω—É—é –∫–∞—Ä—Ç–∏–Ω—É –ø–æ –≤–æ–ø—Ä–æ—Å—É)
            
            –ò–°–¢–û–ß–ù–ò–ö–ò:
            ‚Ä¢ –ê–≤—Ç–æ—Ä 1 (–¥–∞—Ç–∞)
            ‚Ä¢ –ê–≤—Ç–æ—Ä 2 (–¥–∞—Ç–∞)
            ‚Ä¢ –ê–≤—Ç–æ—Ä 3 (–¥–∞—Ç–∞)
            """
            
            prompt = PromptTemplate(
                input_variables=["question", "context"],
                template=template
            )

            # –°–æ–∑–¥–∞–µ–º —Ü–µ–ø–æ—á–∫—É –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞
            chain = LLMChain(
                llm=self.llm,
                prompt=prompt
            )
            
            # –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            print(f"–û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ –º–æ–¥–µ–ª–∏ {self.llm.model_name}: {query}")
            
            # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç
            raw_response = chain.run(
                question=query,
                context=context_text
            )
            
            # –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            print(f"–ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏ –¥–ª–∏–Ω–æ–π {len(raw_response)} —Å–∏–º–≤–æ–ª–æ–≤")
            
            return self._format_structured_response(raw_response, final_docs)
            
        except Exception as e:
            print(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {e}")
            # –ë–æ–ª–µ–µ –ø–æ–¥—Ä–æ–±–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –æ—à–∏–±–∫–µ
            import traceback
            traceback.print_exc()
            return self._format_error_response("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.")

    def compare_opinions(self, query: str) -> str:
        """–°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –º–Ω–µ–Ω–∏–π —Ä–∞–∑–Ω—ã—Ö –∞–≤—Ç–æ—Ä–æ–≤."""
        # –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        print(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–Ω–µ–Ω–∏–π: {query}")
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º –±–æ–ª—å—à–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            docs = self.vectorstore.similarity_search(query, k=20)
            
            if not docs or len(docs) == 0:
                return self._format_error_response("–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞")
            
            # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∫ —Ç–µ–º–µ
            filtered_docs = []
            for doc in docs:
                text = doc.page_content.lower()
                if any(keyword in text for keyword in CRYPTO_KEYWORDS) or 'vitalik' in doc.metadata['author'].lower():
                    filtered_docs.append(doc)
            
            # –ï—Å–ª–∏ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –æ—Å—Ç–∞–ª–æ—Å—å –º–∞–ª–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, –≤–µ—Ä–Ω–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ
            if len(filtered_docs) < 3:
                filtered_docs = docs[:15]  # –í–æ–∑—å–º–µ–º —Ö–æ—Ç—è –±—ã –ø–µ—Ä–≤—ã–µ 15
                print("–ú–∞–ª–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –æ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–∞—Ö –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")
            else:
                print(f"–û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ {len(filtered_docs)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –æ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–∞—Ö")
            
            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –∞–≤—Ç–æ—Ä–∞–º
            authors_map = {}
            for doc in filtered_docs:
                author = doc.metadata["author"]
                if author not in authors_map:
                    authors_map[author] = []
                authors_map[author].append(doc)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —É –Ω–∞—Å –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã 2 –∞–≤—Ç–æ—Ä–∞ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            if len(authors_map) < 2:
                print(f"–ù–∞–π–¥–µ–Ω–æ —Ç–æ–ª—å–∫–æ {len(authors_map)} –∞–≤—Ç–æ—Ä–æ–≤, –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è")
                return self._format_error_response("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∞–≤—Ç–æ—Ä–æ–≤ –¥–ª—è —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞. –ù–∞–π–¥–µ–Ω–æ —Ç–æ–ª—å–∫–æ –º–Ω–µ–Ω–∏–µ " + 
                                                  list(authors_map.keys())[0] if authors_map else "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–≥–æ –∞–≤—Ç–æ—Ä–∞")

            # –û—Ç–±–∏—Ä–∞–µ–º –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –æ—Ç –∫–∞–∂–¥–æ–≥–æ –∞–≤—Ç–æ—Ä–∞ (–Ω–µ –±–æ–ª–µ–µ 3)
            for author in authors_map:
                if len(authors_map[author]) > 3:
                    authors_map[author] = authors_map[author][:3]

            # –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            print(f"–ê–≤—Ç–æ—Ä—ã –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è ({len(authors_map)}): {', '.join(authors_map.keys())}")
            for author, docs_list in authors_map.items():
                print(f"- {author}: {len(docs_list)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")

            # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            prompt_parts = []
            for author, texts in authors_map.items():
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ç–µ–∫—Å—Ç—ã —Å –º–µ—Ç–∫–∞–º–∏ –¥–∞—Ç –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
                author_texts = []
                for doc in texts:
                    author_texts.append(f"[{doc.metadata['date']}] {doc.page_content}")
                
                combined_text = "\n".join(author_texts)
                prompt_parts.append(f"–ê–≤—Ç–æ—Ä: {author}\n–¢–µ–∫—Å—Ç—ã: {combined_text}\n")

            # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞, –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª—å—é
            template = """
            –¢—ã - –æ–ø—ã—Ç–Ω—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–Ω–æ–≥–æ —Ä—ã–Ω–∫–∞ —Å –≥–ª—É–±–æ–∫–∏–º –ø–æ–Ω–∏–º–∞–Ω–∏–µ–º —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π –±–ª–æ–∫—á–µ–π–Ω. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –≤—ã–ø–æ–ª–Ω–∏—Ç—å —Ç—â–∞—Ç–µ–ª—å–Ω—ã–π —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –º–Ω–µ–Ω–∏–π —Ä–∞–∑–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –ø–æ –∑–∞–¥–∞–Ω–Ω–æ–π —Ç–µ–º–µ.
            
            –¢–ï–ú–ê –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê: {query}
            
            –ú–ù–ï–ù–ò–Ø –≠–ö–°–ü–ï–†–¢–û–í:
            {opinions}
            
            –ü—Ä–æ–≤–µ–¥–∏ –≥–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑, –∫–æ—Ç–æ—Ä—ã–π –¥–æ–ª–∂–µ–Ω:
            1. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¢–û–õ–¨–ö–û –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤, –±–µ–∑ –≤–Ω–µ—à–Ω–∏—Ö –∑–Ω–∞–Ω–∏–π
            2. –í—ã–¥–µ–ª–∏—Ç—å –∫–ª—é—á–µ–≤—ã–µ –ø–æ–∑–∏—Ü–∏–∏ –∫–∞–∂–¥–æ–≥–æ –∞–≤—Ç–æ—Ä–∞ —Å –ø—Ä—è–º—ã–º–∏ —Ü–∏—Ç–∞—Ç–∞–º–∏ –ø–æ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏
            3. –ù–∞–π—Ç–∏ –∫–∞–∫ —Ç–æ—á–∫–∏ —Å–æ–≥–ª–∞—Å–∏—è, —Ç–∞–∫ –∏ –∫–ª—é—á–µ–≤—ã–µ —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è –≤–æ –º–Ω–µ–Ω–∏—è—Ö
            4. –°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –æ–±—ä–µ–∫—Ç–∏–≤–Ω–æ–µ –∑–∞–∫–ª—é—á–µ–Ω–∏–µ, –æ—Å–Ω–æ–≤–∞–Ω–Ω–æ–µ –Ω–∞ –∞–Ω–∞–ª–∏–∑–µ –≤—Å–µ—Ö –º–Ω–µ–Ω–∏–π
            5. –ï—Å–ª–∏ –≤ —Ç–µ–∫—Å—Ç–∞—Ö –Ω–µ—Ç —è–≤–Ω—ã—Ö –º–Ω–µ–Ω–∏–π –ø–æ –∑–∞–¥–∞–Ω–Ω–æ–π —Ç–µ–º–µ, —á–µ—Å—Ç–Ω–æ —É–∫–∞–∑–∞—Ç—å –Ω–∞ —ç—Ç–æ
            
            –°–¢–†–£–ö–¢–£–†–ê –û–¢–í–ï–¢–ê (—Å–ª–µ–¥—É–π –µ–π —Å—Ç—Ä–æ–≥–æ):
            
            –û–°–ù–û–í–ù–û–ô –í–´–í–û–î: (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, —Ä–µ–∑—é–º–∏—Ä—É—é—â–∏—Ö –æ—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–Ω–¥–µ–Ω—Ü–∏–∏ –≤ –º–Ω–µ–Ω–∏—è—Ö —ç–∫—Å–ø–µ—Ä—Ç–æ–≤)
            
            –ü–û–ó–ò–¶–ò–ò –ê–í–¢–û–†–û–í:
            ‚Ä¢ [–ò–º—è –∞–≤—Ç–æ—Ä–∞ 1]: (—Ç–æ—á–Ω–æ–µ –∏–∑–ª–æ–∂–µ–Ω–∏–µ –µ–≥–æ –∫–ª—é—á–µ–≤—ã—Ö –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ —Å –¥–∞—Ç–∞–º–∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–π)
            ‚Ä¢ [–ò–º—è –∞–≤—Ç–æ—Ä–∞ 2]: (—Ç–æ—á–Ω–æ–µ –∏–∑–ª–æ–∂–µ–Ω–∏–µ –µ–≥–æ –∫–ª—é—á–µ–≤—ã—Ö –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ —Å –¥–∞—Ç–∞–º–∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–π)
            
            –ö–õ–Æ–ß–ï–í–´–ï –†–ê–°–•–û–ñ–î–ï–ù–ò–Ø:
            ‚Ä¢ –†–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–µ 1: (–ê–≤—Ç–æ—Ä X —Å—á–∏—Ç–∞–µ—Ç ____, –≤ —Ç–æ –≤—Ä–µ–º—è –∫–∞–∫ –ê–≤—Ç–æ—Ä Y —É—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç ____)
            ‚Ä¢ –†–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–µ 2: (–µ—Å–ª–∏ –ø—Ä–∏–º–µ–Ω–∏–º–æ)
            
            –û–ë–©–ò–ï –¢–ï–ù–î–ï–ù–¶–ò–ò:
            ‚Ä¢ –¢–µ–Ω–¥–µ–Ω—Ü–∏—è 1: (—Ç–æ—á–∫–∏ —Å–æ–≥–ª–∞—Å–∏—è –º–µ–∂–¥—É –∞–≤—Ç–æ—Ä–∞–º–∏)
            ‚Ä¢ –¢–µ–Ω–¥–µ–Ω—Ü–∏—è 2: (–µ—Å–ª–∏ –ø—Ä–∏–º–µ–Ω–∏–º–æ)
            
            –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï: (3-4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –æ–±–æ–±—â–∞—é—â–∏–µ –∞–Ω–∞–ª–∏–∑ –∏ —Ä–∞—Å–∫—Ä—ã–≤–∞—é—â–∏–µ –±–æ–ª–µ–µ –≥–ª—É–±–æ–∫–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ —Ç–µ–º—ã)
            
            –ò–°–¢–û–ß–ù–ò–ö–ò:
            ‚Ä¢ [–ò–º—è –∞–≤—Ç–æ—Ä–∞ 1]
            ‚Ä¢ [–ò–º—è –∞–≤—Ç–æ—Ä–∞ 2]
            """

            prompt = PromptTemplate(
                input_variables=["query", "opinions"],
                template=template
            )

            # –°–æ–∑–¥–∞–µ–º —Ü–µ–ø–æ—á–∫—É –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            chain = LLMChain(
                llm=self.llm,
                prompt=prompt
            )

            # –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            print(f"–û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ –º–æ–¥–µ–ª–∏ {self.llm.model_name} –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–Ω–µ–Ω–∏–π –ø–æ —Ç–µ–º–µ: {query}")
            
            # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç
            raw_response = chain.run(
                query=query,
                opinions="\n".join(prompt_parts)
            )
            
            # –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            print(f"–ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏ –¥–ª–∏–Ω–æ–π {len(raw_response)} —Å–∏–º–≤–æ–ª–æ–≤")
            
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç (—ç–º–æ–¥–∑–∏ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞)
            all_docs = []
            for author_docs in authors_map.values():
                all_docs.extend(author_docs)
            
            return self._format_structured_response(raw_response, all_docs)
        except Exception as e:
            print(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–æ–º –∞–Ω–∞–ª–∏–∑–µ: {e}")
            # –ë–æ–ª–µ–µ –ø–æ–¥—Ä–æ–±–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –æ—à–∏–±–∫–µ
            import traceback
            traceback.print_exc()
            return self._format_error_response("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.")

    def _format_structured_response(self, raw_response: str, docs: List[Document]) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç —Å —ç–º–æ–¥–∑–∏ –∏ –º–µ—Ç–∫–∞–º–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤."""
        # –£–¥–∞–ª—è–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ —Å–ª—É–∂–µ–±–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –∏ –≤—Å—Ç—É–ø–∏—Ç–µ–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç
        cleaned_response = raw_response
        
        # –£–¥–∞–ª—è–µ–º –Ω–∞—á–∞–ª—å–Ω—ã–µ —Ñ—Ä–∞–∑—ã, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –æ—Å—Ç–∞–≤–∞—Ç—å—Å—è –æ—Ç —à–∞–±–ª–æ–Ω–∞
        service_prefixes = [
            "–í–æ—Ç –∞–Ω–∞–ª–∏–∑ –ø–æ –∑–∞–¥–∞–Ω–Ω–æ–π —Ç–µ–º–µ:",
            "–í–æ—Ç –æ—Ç–≤–µ—Ç –Ω–∞ –≤–∞—à –≤–æ–ø—Ä–æ—Å:",
            "–í–æ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É:",
            "–í–æ—Ç –º–æ–π –æ—Ç–≤–µ—Ç:",
            "–í–æ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞:",
            "–ù–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö,"
        ]
        
        for prefix in service_prefixes:
            if cleaned_response.startswith(prefix):
                cleaned_response = cleaned_response[len(prefix):].strip()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ –æ—Ç–≤–µ—Ç –æ—Å–Ω–æ–≤–Ω—ã–µ —Å–µ–∫—Ü–∏–∏
        sections = [
            "–û–°–ù–û–í–ù–û–ô –í–´–í–û–î:", 
            "–ü–û–ó–ò–¶–ò–ò –ê–í–¢–û–†–û–í:", 
            "–ö–õ–Æ–ß–ï–í–´–ï –†–ê–°–•–û–ñ–î–ï–ù–ò–Ø:", 
            "–û–ë–©–ò–ï –¢–ï–ù–î–ï–ù–¶–ò–ò:", 
            "–ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï:", 
            "–ò–°–¢–û–ß–ù–ò–ö–ò:"
        ]
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —ç–º–æ–¥–∑–∏ –∫ —Å–µ–∫—Ü–∏—è–º
        emoji_map = {
            "–û–°–ù–û–í–ù–û–ô –í–´–í–û–î:": "üìå ",
            "–ü–û–ó–ò–¶–ò–ò –ê–í–¢–û–†–û–í:": "üë§ ",
            "–ö–õ–Æ–ß–ï–í–´–ï –†–ê–°–•–û–ñ–î–ï–ù–ò–Ø:": "‚öîÔ∏è ",
            "–û–ë–©–ò–ï –¢–ï–ù–î–ï–ù–¶–ò–ò:": "üîÑ ",
            "–ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï:": "üéØ ",
            "–ò–°–¢–û–ß–ù–ò–ö–ò:": "üìö "
        }
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Å–µ–∫—Ü–∏–π –∏ –¥–æ–±–∞–≤–ª—è–µ–º —ç–º–æ–¥–∑–∏
        for section in sections:
            if section in cleaned_response:
                cleaned_response = cleaned_response.replace(section, emoji_map.get(section, "") + section)
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏
        unique_authors = set()
        for doc in docs:
            if 'author' in doc.metadata:
                unique_authors.add(doc.metadata['author'])
        
        sources_text = "\n\nüìö –ò–°–¢–û–ß–ù–ò–ö–ò:\n"
        for author in unique_authors:
            sources_text += f"‚Ä¢ {author}\n"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ —Å–µ–∫—Ü–∏—è –ò–°–¢–û–ß–ù–ò–ö–ò –≤ –æ—Ç–≤–µ—Ç–µ
        if "üìö –ò–°–¢–û–ß–ù–ò–ö–ò:" not in cleaned_response:
            cleaned_response += sources_text
        
        # –£–¥–∞–ª—è–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
        cleaned_response = re.sub(r'\n{3,}', '\n\n', cleaned_response)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∑–∞–∫–ª—é—á–µ–Ω–∏–µ, –µ—Å–ª–∏ –Ω–µ—Ç - –¥–æ–±–∞–≤–ª—è–µ–º
        if "üéØ –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï:" not in cleaned_response:
            # –ù–∞—Ö–æ–¥–∏–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Å–µ–∫—Ü–∏—é –ø–µ—Ä–µ–¥ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏
            last_section_pos = -1
            for section in ["–û–ë–©–ò–ï –¢–ï–ù–î–ï–ù–¶–ò–ò:", "–ö–õ–Æ–ß–ï–í–´–ï –†–ê–°–•–û–ñ–î–ï–ù–ò–Ø:", "–ü–û–ó–ò–¶–ò–ò –ê–í–¢–û–†–û–í:"]:
                section_pos = cleaned_response.find(emoji_map.get(section, "") + section)
                if section_pos > last_section_pos:
                    last_section_pos = section_pos
            
            # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ –ø–æ–∑–∏—Ü–∏—é, –¥–æ–±–∞–≤–ª—è–µ–º –∑–∞–∫–ª—é—á–µ–Ω–∏–µ –ø–µ—Ä–µ–¥ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏
            if last_section_pos != -1:
                sources_pos = cleaned_response.find("üìö –ò–°–¢–û–ß–ù–ò–ö–ò:")
                if sources_pos != -1:
                    conclusion = "\n\nüéØ –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï:\n–ù–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å –≤—ã–≤–æ–¥, —á—Ç–æ –º–Ω–µ–Ω–∏—è —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –ø–æ –¥–∞–Ω–Ω–æ–π —Ç–µ–º–µ —Ä–∞—Å—Ö–æ–¥—è—Ç—Å—è. –ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É—á–∏—Ç—ã–≤–∞—Ç—å —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è –ø—Ä–∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–∏ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –º–Ω–µ–Ω–∏—è.\n"
                    cleaned_response = cleaned_response[:sources_pos] + conclusion + cleaned_response[sources_pos:]
        
        return cleaned_response

    def _format_error_response(self, error_message: str) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –æ–± –æ—à–∏–±–∫–µ."""
        return f"""
‚ùå –û—à–∏–±–∫–∞: {error_message}

–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ:
1. –ü–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–∞—à –≤–æ–ø—Ä–æ—Å
2. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥—Ä—É–≥–∏–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
3. –ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –ø–æ –¥—Ä—É–≥–æ–π —Ç–µ–º–µ

–ï—Å–ª–∏ –ø—Ä–æ–±–ª–µ–º–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è, –¥–∞–π—Ç–µ –º–Ω–µ –∑–Ω–∞—Ç—å, –∏ —è –ø–æ–º–æ–≥—É –≤–∞–º —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å.
"""


def main():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è RAG-–ø–∞–π–ø–ª–∞–π–Ω–∞."""
    import argparse
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
    load_dotenv()
    
    # –°–æ–∑–¥–∞–µ–º –ø–∞—Ä—Å–µ—Ä –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
    parser = argparse.ArgumentParser(description="RAG-—Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π")
    parser.add_argument("--model", "-m", type=str, default="phi", choices=list(LLMFactory.AVAILABLE_MODELS.keys()),
                        help="–Ø–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è (phi, gemma, qwen, saiga)")
    parser.add_argument("--query", "-q", type=str, default="–ö–∞–∫–∏–µ —Ç–µ–Ω–¥–µ–Ω—Ü–∏–∏ –Ω–∞–±–ª—é–¥–∞—é—Ç—Å—è –≤ Ethereum?",
                        help="–ó–∞–ø—Ä–æ—Å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
    parser.add_argument("--mode", type=str, default="qa", choices=["qa", "compare"],
                        help="–†–µ–∂–∏–º –∞–Ω–∞–ª–∏–∑–∞: qa (–≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç) –∏–ª–∏ compare (—Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–Ω–µ–Ω–∏–π)")
    parser.add_argument("--temperature", "-t", type=float, default=0.7,
                        help="–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (0.0-1.0)")
    
    # –ü–∞—Ä—Å–∏–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã
    args = parser.parse_args()
    
    # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    print(f"–ú–æ–¥–µ–ª—å: {LLMFactory.AVAILABLE_MODELS[args.model]['name']}")
    print(f"–ó–∞–ø—Ä–æ—Å: {args.query}")
    print(f"–†–µ–∂–∏–º: {args.mode}")
    print(f"–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞: {args.temperature}")
    print("-" * 50)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–∞–π–ø–ª–∞–π–Ω —Å –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é
    pipeline = RAGPipeline(model_id=args.model, temperature=args.temperature)
    
    # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–µ–∂–∏–º–∞
    if args.mode == "qa":
        print("\n=== –û—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å ===")
        answer = pipeline.generate_qa_response(args.query)
        print(answer)
    else:
        print("\n=== –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ ===")
        analysis = pipeline.compare_opinions(args.query)
        print(analysis)


if __name__ == "__main__":
    main() 